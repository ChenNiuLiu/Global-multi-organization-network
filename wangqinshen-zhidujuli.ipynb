{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d30bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'F:\\Gdelt-ergm\\18_19ERGMedges.csv')\n",
    "\n",
    "# Pivot the data\n",
    "parent_distance = data.pivot_table(values='p', index='node1', columns='node2')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "parent_distance.fillna(0, inplace=True)\n",
    "\n",
    "parent_distance.to_csv(r'F:\\Gdelt-ergm\\parent_relationship.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "648c2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        node1                               node2  contig        dist\n",
      "0      UNICEF                              UNICEF       0  1161.07400\n",
      "1      UNICEF                WORLD ECONOMIC FORUM       0  6272.28500\n",
      "2      UNICEF                             ABB LTD       0  6272.28500\n",
      "3      UNICEF           WORLD HEALTH ORGANIZATION       0  6272.28500\n",
      "4      UNICEF               ACTION AGAINST HUNGER       0  1161.07400\n",
      "...       ...                                 ...     ...         ...\n",
      "89995    YWCA                            INTERSOS       0   748.71170\n",
      "89996    YWCA                      CITRIX SYSTEMS       0  6272.28500\n",
      "89997    YWCA                     HUTCHISON ESSAR       0  6249.01300\n",
      "89998    YWCA  BANK FOR INTERNATIONAL SETTLEMENTS       0    76.42681\n",
      "89999    YWCA                                YWCA       0    76.42681\n",
      "\n",
      "[90000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r'F:\\Gdelt-ergm\\18_19ERGMFINAL.csv')\n",
    "\n",
    "dist_cepii = pd.read_excel(r'F:\\Gdelt-ergm\\dist_cepii.xls')\n",
    "\n",
    "# Combine Source and Target into a single node column\n",
    "nodes = pd.concat([data[\"Source\"], data[\"Target\"]]).unique()\n",
    "\n",
    "# Create a DataFrame from the unique nodes\n",
    "nodes_df = pd.DataFrame(nodes, columns=[\"node\"])\n",
    "\n",
    "# Create a dictionary to map node names to their corresponding codes\n",
    "code_mapping = dict()\n",
    "for index, row in data.iterrows():\n",
    "    code_mapping[row[\"Source\"]] = row[\"SourceCode\"]\n",
    "    code_mapping[row[\"Target\"]] = row[\"TargetCode\"]\n",
    "\n",
    "# Add the 'code' column to the nodes DataFrame using the map() function\n",
    "nodes_df[\"code\"] = nodes_df[\"node\"].map(code_mapping)\n",
    "\n",
    "# Perform a self-join (Cartesian product) on the nodes_df DataFrame\n",
    "node_pairs_df = nodes_df.merge(nodes_df, how='cross')\n",
    "\n",
    "# Rename the columns to 'node1', 'code1', 'node2', 'code2'\n",
    "node_pairs_df.columns = ['node1', 'code1', 'node2', 'code2']\n",
    "\n",
    "# Merge node_pairs_df with dist_cepii to add the 'dist' column\n",
    "node_pairs_with_dist_df = node_pairs_df.merge(\n",
    "    dist_cepii, left_on=['code1', 'code2'], right_on=['iso_o', 'iso_d'], how='left'\n",
    ")\n",
    "\n",
    "# Drop the unnecessary 'iso_o' and 'iso_d' columns\n",
    "node_pairs_with_dist_df.drop(['code1','code2','iso_o', 'iso_d','comlang_off','comlang_ethno','colony','comcol','curcol','col45','smctry','distcap','distw','distwces'], axis=1, inplace=True)\n",
    "\n",
    "# Print the result\n",
    "print(node_pairs_with_dist_df)\n",
    "node_pairs_with_dist_df.to_csv(r'F:\\Gdelt-ergm\\node_pairs_with_dist_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc36744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contig matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Dist matrix:\n",
      "[[ 1161.074    6272.285    6272.285   ... 11761.81     6272.285\n",
      "   6272.285  ]\n",
      " [ 6272.285      76.42681    76.42681 ...  6249.013      76.42681\n",
      "     76.42681]\n",
      " [ 6272.285      76.42681    76.42681 ...  6249.013      76.42681\n",
      "     76.42681]\n",
      " ...\n",
      " [11761.81     6249.013    6249.013   ...   681.9816   6249.013\n",
      "   6249.013  ]\n",
      " [ 6272.285      76.42681    76.42681 ...  6249.013      76.42681\n",
      "     76.42681]\n",
      " [ 6272.285      76.42681    76.42681 ...  6249.013      76.42681\n",
      "     76.42681]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a mapping of node names to integer indices\n",
    "node_index_mapping = {node: i for i, node in enumerate(nodes_df['node'])}\n",
    "\n",
    "# Add 'index1' and 'index2' columns to the DataFrame using the mapping\n",
    "node_pairs_with_dist_df['index1'] = node_pairs_with_dist_df['node1'].map(node_index_mapping)\n",
    "node_pairs_with_dist_df['index2'] = node_pairs_with_dist_df['node2'].map(node_index_mapping)\n",
    "\n",
    "# Fill missing values in the 'contig' column with 0\n",
    "node_pairs_with_dist_df['contig'] = node_pairs_with_dist_df['contig'].fillna(0)\n",
    "\n",
    "# Fill missing values in the 'dist' column with the maximum value plus one\n",
    "max_dist = node_pairs_with_dist_df['dist'].max()\n",
    "node_pairs_with_dist_df['dist'] = node_pairs_with_dist_df['dist'].fillna(max_dist + 1)\n",
    "\n",
    "# Pivot the DataFrame to create the 300x300 matrices for 'contig' and 'dist'\n",
    "contig_matrix = node_pairs_with_dist_df.pivot(index='index1', columns='index2', values='contig').values\n",
    "dist_matrix = node_pairs_with_dist_df.pivot(index='index1', columns='index2', values='dist').values\n",
    "\n",
    "# Convert the matrices to NumPy arrays of shape (300, 300)\n",
    "contig_matrix = np.array(contig_matrix)\n",
    "dist_matrix = np.array(dist_matrix)\n",
    "\n",
    "# Print the matrices\n",
    "print(\"Contig matrix:\")\n",
    "print(contig_matrix)\n",
    "\n",
    "print(\"\\nDist matrix:\")\n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50e90dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matrices to CSV files\n",
    "np.savetxt(r'F:\\Gdelt-ergm\\contig_matrix.csv', contig_matrix, delimiter=',')\n",
    "np.savetxt(r'F:\\Gdelt-ergm\\dist_matrix.csv', dist_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a12c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      "Empty DataFrame\n",
      "Columns: [node1, node2, contig, dist, index1, index2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for missing data in node_pairs_with_dist_df\n",
    "missing_data = node_pairs_with_dist_df[node_pairs_with_dist_df.isnull().any(axis=1)]\n",
    "print(\"Missing data:\")\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11273147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
